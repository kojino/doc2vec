{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "from gensim.models import doc2vec\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(881981, 18)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints = pd.read_csv(\"Consumer_Complaints.csv\")\n",
    "complaints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187645, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints = complaints[complaints[\"Consumer complaint narrative\"].notnull()]\n",
    "complaints.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_complaints, test_complaints = train_test_split(\n",
    "    complaints, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_narratives = train_complaints[\"Consumer complaint narrative\"]\n",
    "test_narratives = test_complaints[\"Consumer complaint narrative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Doc2Vec hyper parameters\n",
    "\n",
    "size = 3 # dimension of the hidden layer (default: 100)\n",
    "window = 5 # max distance between the predicted word and context words (default: 5)\n",
    "min_count = 5 # ignore all words with total frequency lower than this (default: 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_narratives = transform(train_complaints[\"Consumer complaint narrative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train model \n",
    "model = doc2vec.Doc2Vec(train_narratives, size = size, window = window, min_count = min_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Document: «We had a loan modification done with Nationstar Mortgage to lower our payments, change to a fixed rate and avoid a foreclosure. But in the long run our payments went up and our mortgage was extended 10 years. Also, I did not receive a copy of the modification.»\n",
      "\n",
      "MOST (142827, 0.8663327097892761): «AnalyzedDocument(words=['there', 'is', 'a', 'negative', 'mark', 'against', 'me', 'that', 'should', 'have', 'been', 'taken', 'off', 'years', 'ago!'], tags=[142827])»\n",
      "\n",
      "MEDIAN (98008, 0.5247979164123535): «AnalyzedDocument(words=['i', 'have', 'had', 'on', 'my', 'credit', 'for', '2+', 'years', 'a', 'charge', 'of', 'xxxx', 'i', 'have', 'questioned', 'this', 'balance', 'numerous', 'times', 'and', 'my', 'response', 'from', 'xxxx', 'hospital', 'is', ';', 'payment', 'in', 'full', 'is', 'required', 'xxxx', 'hospital', 'accepted', 'a', 'negotiated', 'balance', 'from', 'the', 'xxxx', 'xxxx', 'via', 'xxxx', 'original', 'bill', 'was', 'xxxx,', 'xxxx', 'insurance', 'pd', 'xxxx', 'hospital', 'xxxx', 'xxxx', 'hospital', 'then', 'turned', 'the', 'diffency', 'balance', 'over', 'to', 'a', 'collection', 'agency,', 'named', 'healthcare', 'collections', 'loc', 'per', 'xxxx', 'insurance,', 'when', 'a', 'claim', 'is', 'negotiated', 'the', 'balance', 'is', 'a', 'write', 'off', 'i', 'have', 'called', 'xxxx', 'hospital,', 'they', 'have', 'since', 'removed', 'the', 'charge', 'from', 'my', 'credit,', 'but', 'they', 'have', 'caused', 'me', 'great', 'financial', 'distress', 'to', 'obtain', 'any', 'type', 'of', 'credit', 'for', '2+', 'years', 'xxxx', 'hospital', '#', 'xxxx', 'healthcare', 'collections', 'llc', 'xxxx', 'thank', 'you,', 'xxxx', 'xxxx', 'xxxx'], tags=[98008])»\n",
      "\n",
      "LEAST (87292, -0.41399234533309937): «AnalyzedDocument(words=['to', 'many', 'of', 'the', 'same', 'inquiry', 'in', 'less', 'than', 'xxxx', 'days', 'please', 'removed'], tags=[87292])»\n",
      "\n",
      "\n",
      "\n",
      "Test Document: «I 've been requesting a mortgage modification with the mortgage company Select Port Folio for several years. I finally received a modification/ assumption I made the first payment XXXX XXXX, 2017. I recently received correspondence from SPS stating they had not received my signed modification documents of which was sent back to them XXXX next day delivery.ThXXXX invoice for associations dues was forwarded to SPS and requested to be paid current as a part of the assumption/ modification. I have been given the run around with this mortgage company. I would appreciate your immediate attention in this urgent matter. Correspondence was also recently received stating they were referring my home to foreclosure as a result of the delinquency. They also stated they would not be applying funds received in the amount of {$2100.00} to the account. I would appreciate your immediate attention in this urgent matter. We also spoke with several SPS relationship managers I was informed I had to take Hud Credit Counseling. I 've owned several homes mortgages were always current. My ex-husband was responsible for the mortgage and he never paid it. See Attachments»\n",
      "\n",
      "MOST (150641, 0.7384321093559265): «AnalyzedDocument(words=['i', 'requested', 'a', 'copy', 'of', 'my', 'report', 'but', 'did', \"n't\", 'recieve', 'it'], tags=[150641])»\n",
      "\n",
      "MEDIAN (79510, 0.42479053139686584): «AnalyzedDocument(words=['my', 'wife', 'xxxx', 'xxxx', 'and', 'i', 'had', 'an', 'auto', 'loan', 'through', 'xxxx', 'xxxx', 'unfortunately,', 'we', 'had', 'to', 'voluntarily', 'surrender', 'this', 'vehicle', 'because', 'we', 'simply', 'could', \"n't\", 'afford', 'the', 'payment', 'a', 'few', 'months', 'after', 'surrendering', 'the', 'vehicle,', 'xxxx', 'xxxx', 'xxxx', 'xxxx', 'xxxx', 'reached', 'out', 'to', 'us', 'in', 'regards', 'to', 'paying', 'the', 'remaining', 'balance', 'we', 'came', 'to', 'an', 'agreement', 'of', '{$13000}', 'a', 'month', 'which', 'we', 'started', 'paying', 'in', 'the', 'xxxx', 'of', '2016', 'since', 'then,', 'legal', 'action', '(', 'judgement', ')', 'was', 'going', 'to', 'be', 'taken', 'against', 'us', 'in', 'order', 'to', 'prevent', 'having', 'a', 'judgement', 'on', 'our', 'credit', 'reports,', 'i', 'reached', 'out', 'to', 'xxxx', 'xxxx', 'xxxx', 'to', 'work', 'something', 'out', 'the', 'agreement', 'was', 'that', 'if', 'we', 'paid', 'the', 'balance', 'in', 'full,', 'the', 'case', 'would', 'be', 'dismissed', 'we', 'paid', 'the', 'account', 'off', 'in', 'full', 'and', 'successfully', 'worked', 'with', 'the', 'staff', 'from', 'xxxx', 'xxxx', 'xxxx', 'which', 'was', 'working', 'to', 'collect', 'the', 'debt', 'for', 'xxxx', 'xxxx', 'i', 'immediately', 'disputed', 'the', 'information', 'as', 'being', 'paid', 'on', 'my', 'credit', 'report', 'through', 'equifax', 'equifax', 'came', 'back', '30', 'days', 'later', 'and', 'informed', 'me', 'that', 'all', 'information', 'was', 'reported', 'correctly,', 'but', 'the', 'account', 'was', 'still', 'not', 'showing', 'as', 'paid', 'after', 'receiving', 'this', 'information,', 'i', 'called', 'xxxx', 'xxxx', 'myself', 'to', 'find', 'out', 'what', 'the', 'problem', 'was', 'the', 'representative', 'informed', 'me', 'that', 'my', 'account', 'was', 'showing', 'a', 'xxxx', 'balance', 'and', 'has', 'been', 'paid', 'in', 'full', 'furthermore,', 'this', 'was', 'showing', 'as', 'a', 'voluntary', 'surrender', 'but', 'has', 'now', 'been', 'updated', 'to', 'a', 'collection', 'this', 'account', 'was', 'paid', 'in', 'full'], tags=[79510])»\n",
      "\n",
      "LEAST (87292, -0.2903287410736084): «AnalyzedDocument(words=['to', 'many', 'of', 'the', 'same', 'inquiry', 'in', 'less', 'than', 'xxxx', 'days', 'please', 'removed'], tags=[87292])»\n",
      "\n",
      "\n",
      "\n",
      "Test Document: «XXXX  attempted to process tge repurchase of my loan which they sent to  XXXX  as a default accidently.   XXXX   refuses to process this even being made aware that an error occured.»\n",
      "\n",
      "MOST (132227, 0.9123940467834473): «AnalyzedDocument(words=['stop', 'ruining', 'my', 'credit'], tags=[132227])»\n",
      "\n",
      "MEDIAN (91491, 0.5684452056884766): «AnalyzedDocument(words=['i', 'repeatedly', 'sent', 'this', 'to', 'xxxx', 'and', 'it', 'still', 'has', 'not', 'been', 'correctedi', 'have', 'called', 'them,', 'faxed', 'them', 'and', 'gone', 'online', 'to', 'no', 'avail', 'see', 'copy', 'of', 'fax', 'below', 'the', 'response', 'was', 'my', 'request', 'was', 'illegible', 'and', 'unclear', '--', '--', '--', '--', '--', '--', '--', '--', '--', '--', '-confidentialexperian', 'dfa', 'teamfax', 'xxxx', 'pages', ':', 'from', ':', 'xxxx', 'xxxx', 'xxxx', 'xxxx', 'xxxx', 'xxxx', 'xxxx', 'xxxx', 'xxxx', ',', 'mi', 'xxxxdob', 'xx/xx/xxxxxxxxh', 'xxxx', 'xxxx', 'cell', 'xxxx', 'xxxxxxxxxxxxsubject:1', 'correct', 'my', 'address', 'delete', 'xxxx', 'xxxx', 'xxxx', 'there', 'has', 'never', 'been', 'an', 'apartment,', 'it', 'is', 'a', 'home', '2', 'correct', 'employment', 'to', ':', 'xxxx', 'xxxx', 'xxxx', 'add', 'a', 'free', 'security', 'freeze', 'to', 'my', 'account', 'since', 'my', 'identity', 'was', 'stolen', '4', 'i', 'am', 'not', 'xxxx', 'military', 'i', 'am', 'a', 'xxxx', 'xxxx', 'xxxx', 'xxxx', '5', 'delete', 'the', 'address', 'xxxx', 'xxxx', 'xxxx,', 'xxxx,', 'mi', 'xxxx', 'i', 'have', 'never', 'lived', 'there', 'this', 'address', 'was', 'reported', 'to', 'you', 'by', 'xxxx', 'it', 'was', 'the', 'address', 'used', 'by', 'the', 'thief', 'that', 'stole', 'my', 'identity', '6', 'put', 'a', 'free', 'security', 'freeze', 'on', 'my', 'account', 'since', 'my', 'identity', 'was', 'stolen', 'enclosures:1', 'mi', 'driver', \"'s\", 'license2', 'homeowners', 'policy3', 'utility', 'bill4', 'police', 'report5', 'xxxx', 'letter', 'stating', 'the', 'account', 'opened', 'in', 'my', 'name', 'is', 'not', 'my', 'account', 'and', 'i', 'am', 'not', 'responsible', 'for', 'the', 'charges'], tags=[91491])»\n",
      "\n",
      "LEAST (87292, -0.4605390429496765): «AnalyzedDocument(words=['to', 'many', 'of', 'the', 'same', 'inquiry', 'in', 'less', 'than', 'xxxx', 'days', 'please', 'removed'], tags=[87292])»\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with new docs\n",
    "test_docvecs = test(test_narratives[:3],train_narratives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(docs_test,docs_original):\n",
    "    docvecs = []\n",
    "    for test_doc in docs_test:\n",
    "        docvec = model.infer_vector(test_doc)\n",
    "        docvecs.append(docvec)\n",
    "        sims = model.docvecs.most_similar([docvec], topn=len(model.docvecs))\n",
    "        print('Test Document: «{}»\\n'.format(test_doc))\n",
    "        for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "            print(u'%s %s: «%s»\\n' % (label, sims[index], docs_original[sims[index][0]]))\n",
    "        print(\"\\n\")\n",
    "    return docvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform data (you can add more data preprocessing steps) \n",
    "def transform(docs_original):\n",
    "    docs = []\n",
    "    analyzedDocument = namedtuple('AnalyzedDocument', 'words tags')\n",
    "    for i, text in enumerate(docs_original):\n",
    "        words = text.lower().replace('.','').split()\n",
    "        tags = [i]\n",
    "        docs.append(analyzedDocument(words, tags))\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
